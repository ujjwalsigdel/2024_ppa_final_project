---
title: "Creating and validating zones"
format: html
---

# Learning Objectives  
Today's objectives are to:  
- **Import** the joined layers

- Perform a clustering analysis called **k-means** to create zones  

- **Assess** how variables are impacting different zones  

- **Validate** zones with yield spatial-temporal stability areas  

# Setup  
```{r setup }
#| message: false
#| warning: false

#install.packages("factoextra")
#install.packages("NbClust")
#install.packages("ggpubr")

# Packages
library(dplyr)
library(tidyr)
library(readr)
library(sf) #vector manipulation
library(ggplot2)
library(viridis)
library(ggthemes)
library(patchwork) #combining multiple plots
library(factoextra)
library(NbClust)
library(ggpubr)
library(tidyverse)
library(knitr)
library(stars)
library(starsExtra)
library(gstat)


```

# Data import  
```{r all_v}
all_v <- read_sf("../data/all_v.geojson")

all_v
```

```{r boundary_w}
boundary <- read_sf("../data/boundary/DR1 boundary.shp") 

boundary
```


# EDA  
```{r summary}
summary(all_v)
```


# Wrangling and standardizing
```{r @ all_v_n}
all_v_n <- all_v %>% 
  # Dropping NA cells
drop_na() %>% 
  # Selecting variables of interest
dplyr::select(elev_m:eca90_dsm,
              -flowdir,
              -aspect) %>% 
  # Standardizing
mutate(across(where(is.numeric) , ~scale(.x)))
  
all_v_n
```

## Defining k  
We need to define the number of clusters we want.  
Let's try 4.  

```{r kmeans initial model }
mod_km <- kmeans(all_v_n %>% 
  st_drop_geometry(),
  centers = 4,
  nstart = 10
  )

mod_km
```
The argument `nstart` defines how many times the algorithm should be run. This is important because of the random nature of selecting the observations on the first step. Having nstart=10 runs the model 10 times and avoids an unfortunate initial random selection that ends up creating clusters that do not represent the true data groups.  

With **k=4**, our between/total SS was 59.9% (greater the better).    
Let's try **k=3** and see what happens: between/total SS was 51.3%.  
**k=5** was 64.5%
What about **k=10**? between/total SS was ...%.

> So let's just select k=10, right?  

So how do we **find the best k** value for a given data set?    

## Finding k  
Since the choice of k can be subjective, we will need to find an **objective** way to select the value of k that most properly represents our data set.  

There are different tests and metrics that can be used to select k.  
All of them run k-means with k ranging from 1 to 10 (in our case), and assess how much information is gained by adding each of the extra groups beyond 1.  

Let's explore a few of these metrics:
```{r finding k - wss method}
# Total error x k
fviz_nbclust(all_v_n %>% 
             st_drop_geometry(),
             method = "wss",
             k.max = 10,
             FUNcluster = kmeans
             ) #elbow method
```

```{r finding k - silhouette method}
# Silhouette width
fviz_nbclust(all_v_n %>%
               st_drop_geometry(), 
             method = "s",
             k.max = 10,
             FUNcluster = kmeans) #4

```
What if different metrics give you a different recommendation on k?  

We can compute multiple metrics, and select the k value recommended by the majority:


Let's go with 4 clusters:
```{r @ mod_km2 }
mod_km2 <- kmeans(all_v_n %>% 
                    st_drop_geometry(),
                  centers = 4,
                  nstart = 10)

mod_km2
```

# Exploring clusters  
Let's save cluster membership as a column in our data, and bring back the geometry so we can map it.  
```{r @ zone_df }
zone_df <- all_v_n %>% 
  # Adding cluster membership column
mutate(cluster = mod_km2$cluster,
       cluster = factor(cluster))

zone_df %>% 
  group_by(cluster) %>% 
  summarize(n = length(cluster))



```


```{r cluster map}
zone_df %>% 
  ggplot()+
  geom_sf(aes(fill = cluster),
          color = NA)+
  scale_fill_colorblind()+
  geom_sf(data = boundary, fill = NA)+
  labs(title = "Unsmoothed zones")+
  theme_map()+
  theme(plot.title = element_text(color = 'blue'))
  
ggsave("../output/zones.png",
       width = 3,
       height = 4,
       bg = "white") #if bg not assigned, it used transparent background
```

# Smoothing zones  
```{r what is a focal window?}
knitr::include_graphics("https://geocompr.robinlovelace.net/figures/04_focal_example.png")

```

```{r grid_r}
library(stars)
#install.packages("abind")
library(abind)
# grid in vector format
grid_r <-  boundary %>%
  st_make_grid(cellsize = 10) %>%
  st_as_sf() %>%
  st_rasterize(dx=10, dy=10) %>%
  st_crop(boundary)

grid_r
```

```{r}
library(dplyr)
library(sf)
library(ggplot2)


# Define matrix sizes and functions
matrix_sizes <- c(3, 5, 7)
functions <- c("min", "max", "mean")

# Loop through each combination of matrix size and function
for(size in matrix_sizes) {
  for(func in functions) {
    # Apply focal filter and create the plot
    plot <- zone_df %>% 
      dplyr::select(cluster) %>% 
      # Transforming from polygon to point
      st_cast("POINT") %>% 
      # Transforming from geometry to xy (needed by the focal function)
      st_sfc2xy() %>% 
      # Transforming from point (vector) to raster
      st_as_stars() %>% 
      # Applying focal filter
      focal2(w = matrix(1, size, size),
             fun = func,
             na.rm = TRUE) %>%         
      # Transforming from raster back to vector
      st_as_sf() %>% 
      # Interpolating to fill to boundary
      gstat::gstat(formula = cluster ~ 1, data = .) %>% 
      predict(grid_r) %>% 
      # Transforming from raster back to vector
      st_as_sf() %>% 
      # Rounding  
      mutate(cluster = round(var1.pred, 0)) %>% 
      # Adjusting cluster id from numeric to factor
      mutate(cluster_f = factor(cluster)) %>%
      ggplot() +
      geom_sf(aes(fill = cluster_f), color = NA) +
      geom_sf(data = boundary, fill = NA) +
      scale_fill_colorblind() +
      labs(title = paste("Smoothed zones,", size, "x", size, ",", func)) +
      theme_map() +
      theme(plot.title = element_text(color = "blue"))

    # Save the plot as an image file
    ggsave(paste("../output/zonesmoothed_", size, "x", size, "_", func, ".png", sep = ""),
           plot,
           width = 6,
           height = 4)
  }
}

```


How are clusters affected by the variables used to create them?  

```{r}
zone_s_df <- all_v %>% 
  st_join(zone_s,
          join = st_equals,
          left = T) %>% 
  dplyr::select(-flowdir, -aspect, -var1.pred, -var1.var, -cluster)

zone_s_df

zone_s_df %>%
  summary
```


```{r cluster x variable boxplots}
zone_s_df %>%
  dplyr::select(-stclass) %>%
  pivot_longer(cols = elev_m:eca90_dsm) %>%
  ggplot(aes(x=cluster_f, y=value, color=cluster_f))+
  geom_boxplot(show.legend = F)+
  scale_color_colorblind()+
  facet_wrap(~name, scales="free_y", ncol=3)+
  stat_compare_means(label = "p.format",
                     hjust = -.1,
                     vjust=1)+
  theme(legend.position = "none")
```

> Based on the plots above and what we established about high- and low-stable classes in the previous exercise, which cluster do you expect that will be higher yielding? Why?    





# Validating clusters  
Ok, so we have 2 clusters that are significantly different based on the variables we used to create them. Great!  

> What does that mean for yield though? 
> Are these two clusters creating different yield levels?  
> How can we test that?  



```{r clusters and standardized yield}
zone_s_df %>%
  pivot_longer(cols = sy17:sy20) %>%
  ggplot(aes(x=cluster_f, y=value, color=cluster_f))+
  geom_boxplot(show.legend = F)+
  scale_color_colorblind()+
  facet_wrap(~name, scales="free_y", ncol=3)+
  stat_compare_means(label = "p.format",
                     hjust = -.1,
                     vjust=1)+
  theme(legend.position = "none")

```

```{r clusters and mean yield and cv }
zone_s_df %>%
  pivot_longer(cols = c(mean_pixel, cv_pixel)) %>%
  ggplot(aes(x=cluster_f, y=value, color=cluster_f))+
  geom_boxplot(show.legend = F)+
  scale_color_colorblind()+
  facet_wrap(~name, scales="free_y", ncol=3)+
  stat_compare_means(label = "p.format",
                     hjust = -.1,
                     vjust=1)+
  theme(legend.position = "none")

```

It seems like cluster 2 has higher CV and lower yield, and cluster 1 has lower CV and greater yield.  

```{r contingency table}
zone_s_df %>%
  group_by(stclass) %>%
  mutate(N=length(stclass)) %>%
  group_by(cluster_f, stclass, N) %>%
  tally() %>%
  mutate(prop=(n/N)*100) %>%
  mutate(prop=round(prop,0)) %>%
  ggplot(aes(x=cluster_f, 
             y=prop, 
             fill=cluster_f))+
  geom_col(position="dodge", color="black")+
  scale_fill_colorblind()+
  facet_grid(~stclass )+
  geom_text(aes(label=paste0(prop,"%"), y=prop+5))+
  theme(legend.position = "none")

```

I suppose we can call cluster 2 as high yield and cluster 1 as lower yield, right?  

```{r contingency table}
zone_s_df %>% 
  group_by(stclass) %>% 
  mutate(N = length(stclass)) %>% 
  group_by(cluster_f, stclass, N) %>% 
  tally() %>% 
  mutate(prop = (n/N)*100) %>% 
  ggplot(aes(x = cluster_f,
             y = prop,
             fill = cluster_f))+
  geom_col()+
  facet_grid(~stclass)
  
``` 
I suppose we can call cluster 1 as high yield and cluster 2 as lower yield, right?

# Exporting clusters  
```{r exporting clusters}
zone_s_df %>% 
  mutate(zone = case_when(
    cluster_f == "1" ~ "high",
    cluster_f == "2" ~ "low"
  )) %>% 
  write_sf("../data/zone_s.geojson",
           delete_dsn = T)
```

# Summary  
Today we:  
- Learned about the k-means algorithm  
- Found the best k for our data set  
- Created k=2 zones  
- Explored the main zone drivers  
- Validated zones with yield spatial-temporal stability areas  
- Explored the main yield stability drivers  

# Next steps  
To wrap up this entire exercise, the next steps will be to:  
- decide how to handle spatial-temporal stability  
- create zone-specific variable rate recommendations  

# Assignment  
